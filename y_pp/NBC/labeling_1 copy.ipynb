{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "day = date(2024, 3, 1)\n",
    "day_dateoffset = day - pd.DateOffset(months=1)\n",
    "print(day_dateoffset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-30\n"
     ]
    }
   ],
   "source": [
    "day = date(2024, 3, 1)\n",
    "day_timedelta = day - timedelta(days=31)\n",
    "print(day_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'price', 'label']\n",
      "['2024-03-21\\t3.5290\\t-0.11\\n', '2024-03-20\\t3.5330\\t0.56\\n', '2024-03-19\\t3.5130\\t2.09\\n', '2024-03-18\\t3.4410\\t-0.66\\n', '2024-03-15\\t3.4640\\t-0.63\\n']\n"
     ]
    }
   ],
   "source": [
    "f = open('call_rate.csv', 'r', encoding='utf-8')\n",
    "\n",
    "# 데이터를 완전히 동일하게 가져올 수 있는가\n",
    "headers = f.readline().rstrip() # 헤더 읽기, 맨 끝 줄바꿈기호 삭제\n",
    "print(headers.split('\\t'))\n",
    "headers = headers.split('\\t') # 같은 이름의 변수에 리스트로 바꾼 것 넣어주기\n",
    "\n",
    "# 데이터 읽기\n",
    "lines = f.readlines()\n",
    "print(lines[:5])\n",
    "\n",
    "new_datas = []\n",
    "for line in lines: # 한 줄씩 \n",
    "    data = line.rstrip().split('\\t') # 줄바꿈 기호 지우고, ,로 잘라준다.\n",
    "    dict_data = { header: data[i] for i, header in enumerate(headers) }\n",
    "    new_datas.append(dict_data) # 데이터를 딕셔너리로 만들어서 넣어야된다.\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_date(df, target_date):\n",
    "    delta = pd.Timedelta(days=1)\n",
    "    nearest_date = None,\n",
    "    min_difference = pd.Timedelta.max\n",
    "\n",
    "    for date in df['date']:\n",
    "        difference = abs(target_date - date)\n",
    "        if difference < min_difference:\n",
    "            min_difference = difference\n",
    "            nearest_date = date\n",
    "\n",
    "    return nearest_date\n",
    "\n",
    "def label_call(df):\n",
    "    df_ud = pd.DataFrame(index=df.index, columns=['date', 'price', 'label'])\n",
    "\n",
    "    # 'date' 열을 datetime 형식으로 변환\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        time = row['date']\n",
    "        time2 = time - pd.DateOffset(months=1)\n",
    "\n",
    "        # 이전 달의 날짜가 인덱스에 있는지 확인\n",
    "        if time2 in df['date'].values:\n",
    "            prev_row = df[df['date'] == time2].iloc[0]\n",
    "        else:\n",
    "            # 이전 날짜가 없는 경우 가장 가까운 날짜로 설정\n",
    "            nearest_date = find_nearest_date(df, time2)\n",
    "            prev_row = df[df['date'] == nearest_date].iloc[0]\n",
    "\n",
    "        if row['price'] > prev_row['price']:\n",
    "            label = '1'\n",
    "        elif row['price'] == prev_row['price']:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = '-1'\n",
    "\n",
    "        df_ud.loc[i] = [time.date(), row['price'], label]\n",
    "\n",
    "    return df_ud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>3.5290</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>3.5330</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>3.5130</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-18</td>\n",
       "      <td>3.4410</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>3.4640</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3258 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   price label\n",
       "0     2024-03-21  3.5290    -1\n",
       "1     2024-03-20  3.5330    -1\n",
       "2     2024-03-19  3.5130    -1\n",
       "3     2024-03-18  3.4410    -1\n",
       "4     2024-03-15  3.4640    -1\n",
       "...          ...     ...   ...\n",
       "3253  2011-01-07  2.4900     0\n",
       "3254  2011-01-06  2.4900     0\n",
       "3255  2011-01-05  2.4900     0\n",
       "3256  2011-01-04  2.5000     1\n",
       "3257  2011-01-03  2.4900     0\n",
       "\n",
       "[3258 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(new_datas)\n",
    "\n",
    "call = label_call(df)\n",
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ekonlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy as kn\n",
    "import MeCab as mc\n",
    "import ekonlpy as ek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pandas import Series, DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'words'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링 결과물 불러오기 - 이데일리 뉴스 \n",
    "from ekonlpy.tag import Mecab\n",
    "from ekonlpy.sentiment import MPCK\n",
    "mpck = MPCK()\n",
    "\n",
    "# 패턴 정의\n",
    "news_pattern = ['\\\\[.*\\\\]','(?<=[가-힣])\\\\.','\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?','....기자']\n",
    "bone_pattern = []\n",
    "\n",
    "result_path = './crawl_result/edaily_news_test.json'\n",
    "df = pd.read_json(result_path)\n",
    "df = df.sort_values(by=[\"date\"], ascending=False) # 날짜별 내림차순\n",
    "\n",
    "# 특정패턴 제거\n",
    "for pattern in news_pattern:\n",
    "    df['content'] = df['content'].apply(lambda x: re.sub(pattern, '', x))\n",
    "news1_df = df\n",
    "\n",
    "news1_df['words']=\" \"  # 빈 값을 가진 words column 추가\n",
    "for i, row in df.iterrows() :\n",
    "    try :\n",
    "        tmp_df = news1_df['content']\n",
    "        #임시 데이터프레임에 불러온 기사의 본문 내용 리스트로 저장\n",
    "        tokens = mpck.tokenize(tmp_df[i])\n",
    "        row['words'] = '.'.join(tokens)\n",
    "        df.loc[i, 'words'] = row['words']\n",
    "        #eKoNLPy로 tokenizing 한 것을 데이터프레임에 column 추가\n",
    "\n",
    "    except Exception as ex :\n",
    "        print(\"fail\")\n",
    "        \n",
    "news1_df = news1_df.drop(['content', 'title'], axis=1)  # axis=1은 열을 의미함\n",
    "news1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'words'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링 결과물 불러오기 - 중앙일보 뉴스 \n",
    "mpck = MPCK()\n",
    "\n",
    "news_pattern = ['\\\\[.*\\\\]','(?<=[가-힣])\\\\.','\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?','....기자']\n",
    "bone_pattern = []\n",
    "\n",
    "result_path = './crawl_result/joongamg_news_test.json'\n",
    "df = pd.read_json(result_path)\n",
    "df = df.sort_values(by=[\"date\"], ascending=False)\n",
    "\n",
    "for pattern in news_pattern:\n",
    "    df['content'] = df['content'].apply(lambda x: re.sub(pattern, '', x))\n",
    "news2_df = df\n",
    "\n",
    "news2_df['words']=\" \"\n",
    "for i, row in df.iterrows() :\n",
    "    try :\n",
    "        tmp_df = news2_df['content']\n",
    "\n",
    "        tokens = mpck.tokenize(tmp_df[i])\n",
    "        row['words'] = '.'.join(tokens)\n",
    "        df.loc[i, 'words'] = row['words']\n",
    "\n",
    "    except Exception as ex :\n",
    "        print(\"fail\")\n",
    "\n",
    "news2_df = news2_df.drop(['content', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'words'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링 결과물 불러오기 - 머니투데이 뉴스 \n",
    "mpck = MPCK()\n",
    "\n",
    "news_pattern = ['\\\\[.*\\\\]','(?<=[가-힣])\\\\.','\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?','....기자']\n",
    "bone_pattern = []\n",
    "\n",
    "result_path = './crawl_result/moneytoday_news_test.json'\n",
    "df = pd.read_json(result_path)\n",
    "df = df.sort_values(by=[\"date\"], ascending=False) \n",
    "\n",
    "for pattern in news_pattern:\n",
    "    df['content'] = df['content'].apply(lambda x: re.sub(pattern, '', x))\n",
    "news3_df = df\n",
    "\n",
    "news3_df['words']=\" \" \n",
    "for i, row in df.iterrows() :\n",
    "\n",
    "    try :\n",
    "        tmp_df = news3_df['content']\n",
    "\n",
    "        tokens = mpck.tokenize(tmp_df[i])\n",
    "        row['words'] = '.'.join(tokens)\n",
    "        df.loc[i, 'words'] = row['words']\n",
    "\n",
    "    except Exception as ex :\n",
    "        print(\"fail\")\n",
    "\n",
    "news3_df = news3_df.drop(['content', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['날짜', 'words'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링 결과물 불러오기 - 의사록 \n",
    "mpck = MPCK()\n",
    "\n",
    "news_pattern = ['\\\\[.*\\\\]','(?<=[가-힣])\\\\.','\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?','....기자']\n",
    "bone_pattern = []\n",
    "\n",
    "result_path = './crawl_result/minutes_re.tsv'\n",
    "df = pd.read_csv(result_path, sep='\\t')\n",
    "\n",
    "for pattern in news_pattern:\n",
    "    df['내용'] = df['내용'].apply(lambda x: re.sub(pattern, '', x))\n",
    "min_df = df\n",
    "\n",
    "min_df['words']=\" \"\n",
    "for i, row in df.iterrows() :\n",
    "    try :\n",
    "        tmp_df = min_df['내용']\n",
    "\n",
    "        tokens = mpck.tokenize(tmp_df[i])\n",
    "        row['words'] = '.'.join(tokens)\n",
    "        df.loc[i, 'words'] = row['words']\n",
    "\n",
    "    except Exception as ex :\n",
    "        print(\"fail\")\n",
    "\n",
    "min_df = min_df.drop('내용', axis=1) \n",
    "min_df = min_df.rename(columns={'날짜': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'words'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링 결과물 불러오기 - 채권 보고서 \n",
    "mpck = MPCK()\n",
    "\n",
    "news_pattern = ['\\\\[.*\\\\]','(?<=[가-힣])\\\\.','\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?','....기자']\n",
    "bone_pattern = []\n",
    "\n",
    "result_path = './crawl_result/text_by_date.json1_test.json'\n",
    "df = pd.read_json(result_path)\n",
    "df = df.sort_values(by=[\"date\"], ascending=False)\n",
    "\n",
    "for pattern in news_pattern:\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(pattern, '', x))\n",
    "bond_df = df\n",
    "\n",
    "bond_df['words']=\" \"\n",
    "for i, row in df.iterrows() :\n",
    "    try :\n",
    "        tmp_df = bond_df['text']\n",
    "\n",
    "        tokens = mpck.tokenize(tmp_df[i])\n",
    "        row['words'] = '.'.join(tokens)\n",
    "        df.loc[i, 'words'] = row['words']\n",
    "\n",
    "    except Exception as ex :\n",
    "        print(\"fail\")\n",
    "\n",
    "bond_df = bond_df.drop('text', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>fed/NNG.fed/NNG.금리/NNG.포인트/NNG.인상/NNG.하/XSV.가운...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>fed/NNG.fed/NNG.금리/NNG.인상/NNG.종료/NNG.시사/NNG.하/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>fed/NNG.fed/NNG.매파/NNG.색채/NNG.드러나/VV.fed/NNG.예...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>fed/NNG.fed/NNG.fed/NNG.금리/NNG.수준/NNG.인상/NNG.하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>fed/NNG.fed/NNG.현지/NNG.개최/NNG.달/NNG.fed/NNG.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>금리/NNG.국고채/NNG.금리/NNG.추이/NNG.일드커브/NNG.형태/NNG.변...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>거래주체/NNG.매매동향/NNG.은행/NNG.순매수/NNG.상위/NNG.은행/NNG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>거래주체/NNG.매매동향/NNG.은행/NNG.순매수/NNG.상위/NNG.은행/NNG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>에너지기업/NNG.유가/NNG.급락/NNG.트레이드/NNG.증권/NNG.본부/NNG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>회사채/NNG.등급별/NNG.분포/NNG.현황/NNG.단위/NNG.개/NNG.구분/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                              words\n",
       "298  2023-05-04  fed/NNG.fed/NNG.금리/NNG.포인트/NNG.인상/NNG.하/XSV.가운...\n",
       "288  2023-05-04  fed/NNG.fed/NNG.금리/NNG.인상/NNG.종료/NNG.시사/NNG.하/...\n",
       "297  2023-05-04  fed/NNG.fed/NNG.매파/NNG.색채/NNG.드러나/VV.fed/NNG.예...\n",
       "296  2023-05-04  fed/NNG.fed/NNG.fed/NNG.금리/NNG.수준/NNG.인상/NNG.하...\n",
       "287  2023-05-04  fed/NNG.fed/NNG.현지/NNG.개최/NNG.달/NNG.fed/NNG.fe...\n",
       "..          ...                                                ...\n",
       "4    2011-01-07  금리/NNG.국고채/NNG.금리/NNG.추이/NNG.일드커브/NNG.형태/NNG.변...\n",
       "3    2011-01-04  거래주체/NNG.매매동향/NNG.은행/NNG.순매수/NNG.상위/NNG.은행/NNG...\n",
       "2    2011-01-02  거래주체/NNG.매매동향/NNG.은행/NNG.순매수/NNG.상위/NNG.은행/NNG...\n",
       "1    2011-01-01  에너지기업/NNG.유가/NNG.급락/NNG.트레이드/NNG.증권/NNG.본부/NNG...\n",
       "0    2011-01-01  회사채/NNG.등급별/NNG.분포/NNG.현황/NNG.단위/NNG.개/NNG.구분/...\n",
       "\n",
       "[1401 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 크롤링 데이터들 -> 데이터프레임으로 합치기\n",
    "crawl = pd.concat([news1_df, news2_df, news3_df, min_df, bond_df])\n",
    "crawl['date'] = pd.to_datetime(crawl['date']).dt.date\n",
    "crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # korean stop words 불러오기\n",
    "# stopwords_path = 'korean_sotp_words.txt'\n",
    "# stopwords = []\n",
    "# with open(stopwords_path, 'r', encoding='utf-8') as file:\n",
    "#     for line in file:\n",
    "#         stopwords.append(line.strip())\n",
    "# print(stopwords)  # 불용어 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word = []\n",
    "# for tag in text: #토큰화된 text\n",
    "#     if tag[1] not in stopwords:\n",
    "#         if tag[0] not in stopwords:\n",
    "#             word.append(tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사 태깅 제거\n",
    "import re\n",
    "\n",
    "def extract_hangul_words(text):\n",
    "    words = ' '.join(re.findall('[가-힣]+', text))\n",
    "    return words\n",
    "\n",
    "crawl['words'] = crawl['words'].apply(extract_hangul_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'price', 'label', 'words'], dtype='object')\n",
      "           date   price label  \\\n",
      "0    2006-05-11     NaN   NaN   \n",
      "1    2006-05-25     NaN   NaN   \n",
      "2    2006-06-08     NaN   NaN   \n",
      "3    2006-06-22     NaN   NaN   \n",
      "4    2006-07-07     NaN   NaN   \n",
      "...         ...     ...   ...   \n",
      "3401 2024-03-15  3.4640    -1   \n",
      "3402 2024-03-18  3.4410    -1   \n",
      "3403 2024-03-19  3.5130    -1   \n",
      "3404 2024-03-20  3.5330    -1   \n",
      "3405 2024-03-21  3.5290    -1   \n",
      "\n",
      "                                                  words  \n",
      "0     조 의거 하 의안 통화정책 방향 상정 하 토의 내용 국내외 경제동향 하 국제 유가 ...  \n",
      "1     담당 보가 지급 결제 원활 위하 금융기관 일중 당좌대출 한도규제 폐지 하 일중 당좌...  \n",
      "2     조 의거 하 의안 통화정책 방향 상정 하 토의 내용 국내외 경제동향 하 경기 선행 ...  \n",
      "3     조건 구비 하 사항 명시 하 차액 결제 참가 기관 자금 조정 적수 보전 이자 정산 ...  \n",
      "4     보 금융시장 동향 대하 보고 내용 별첨 조 의거 하 의안 통화정책 방향 상정 하 토...  \n",
      "...                                                 ...  \n",
      "3401  가명 아이 낳 신생아 특례 대출 받 대기업 근무 하 같 남편 소득 합하 달하 신생아...  \n",
      "3402                                                NaN  \n",
      "3403                                                NaN  \n",
      "3404                                                NaN  \n",
      "3405  업 비트 라운지 비트코인 시세 나오 뉴스 하락 보 가상화폐 비트코인 현지 미 금리 ...  \n",
      "\n",
      "[3406 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 콜금리에 date기준으로 크롤링 칼럼 추가하기\n",
    "import pandas as pd\n",
    "\n",
    "# Date 열을 datetime으로 변환하고 인덱스로 설정\n",
    "call['date'] = pd.to_datetime(call['date'])\n",
    "call.set_index('date', inplace=True)\n",
    "\n",
    "crawl['date'] = pd.to_datetime(crawl['date'])\n",
    "crawl.set_index('date', inplace=True)\n",
    "\n",
    "# 중복된 인덱스 제거\n",
    "call = call[~call.index.duplicated()]\n",
    "crawl = crawl[~crawl.index.duplicated()]\n",
    "\n",
    "# 동일한 날짜에 대해 열을 합치기\n",
    "merged_df = pd.concat([call, crawl], axis=1)\n",
    "\n",
    "# 'date' 열을 다시 열로 변환\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(merged_df.columns)\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'label' 칼럼의 값이 '1(매파)'인 행과 '-1(비둘기파)'인 행으로 데이터프레임 분리\n",
    "df_P = merged_df[merged_df['label'] == '1']\n",
    "df_N = merged_df[merged_df['label'] == '-1']\n",
    "\n",
    "# Nan인 행 제거\n",
    "df_P = df_P.dropna()\n",
    "df_N = df_N.dropna()\n",
    "\n",
    "# 필요없는 열 제거 \n",
    "df_P = df_P.drop(['date', 'price'], axis=1)\n",
    "df_N = df_N.drop(['date', 'price'], axis=1)\n",
    "\n",
    "word_df = pd.concat([df_P,df_N],axis=0)\n",
    "x_tain = word_df[\"words\"]\n",
    "y_tain = word_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>은행</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>순매수</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>상위</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>순매도</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>보험기금</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>병목</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>오미크론</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>우크라이나사태</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>빈일자리</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>오프닝</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1703 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Frequency\n",
       "0          은행        843\n",
       "1         순매수        153\n",
       "2          상위         93\n",
       "3         순매도        132\n",
       "4        보험기금         22\n",
       "...       ...        ...\n",
       "1698       병목         30\n",
       "1699     오미크론         27\n",
       "1700  우크라이나사태         77\n",
       "1701     빈일자리         26\n",
       "1702      오프닝         50\n",
       "\n",
       "[1703 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매파 words 빈도수 체크 \n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# 텍스트 칼럼에서 단어 횟수 세기\n",
    "text = ' '.join(df_P['words'])  # 텍스트 칼럼의 모든 텍스트를 하나의 문자열로 결합\n",
    "tokens = word_tokenize(text)  # 텍스트를 단어로 토큰화\n",
    "word_counts = Counter(tokens)  # 단어 등장 횟수 카운트\n",
    "\n",
    "# 빈도수가 15 이상인 단어 필터링\n",
    "filtered_word_counts = {word: count for word, count in word_counts.items() if count >= 15}\n",
    "\n",
    "df_P_counts = pd.DataFrame(filtered_word_counts.items(), columns=['Word', 'Frequency'])\n",
    "df_P_counts['P'] = 1 # 라벨링 다시 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_P_counts.to_csv(\"hawkish_count_1.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>표</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>만기</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사채</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>종목</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>신용등급</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>대면</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>변이</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>자녀</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>전기차</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>홍콩</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1944 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frequency\n",
       "0        표         37\n",
       "1       만기        157\n",
       "2      회사채        440\n",
       "3       종목         24\n",
       "4     신용등급         94\n",
       "...    ...        ...\n",
       "1939    대면         21\n",
       "1940    변이         17\n",
       "1941    자녀         24\n",
       "1942   전기차         37\n",
       "1943    홍콩         18\n",
       "\n",
       "[1944 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비둘기파 words 빈도수 체크\n",
    "text = ' '.join(df_N['words'])  # 텍스트 칼럼의 모든 텍스트를 하나의 문자열로 결합\n",
    "tokens = word_tokenize(text)  # 텍스트를 단어로 토큰화\n",
    "word_counts = Counter(tokens)  # 단어 등장 횟수 카운트\n",
    "\n",
    "# 빈도수가 15 이상인 단어 필터링\n",
    "filtered_word_counts = {word: count for word, count in word_counts.items() if count >= 15}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df_N_counts = pd.DataFrame(filtered_word_counts.items(), columns=['Word', 'Frequency'])\n",
    "df_N_counts['N'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_B_counts.to_csv(\"dovish_count_1.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>순매수 상위</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>순매도 상위</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>상위 보험기금</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>상위 투신</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>상위 외국인</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>물가 둔화</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>목 목</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>리 오프닝</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>인플레이션 둔화</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>특례 보금자리론</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3088 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ngram  frequency  N\n",
       "0       순매수 상위         44  1\n",
       "1       순매도 상위         44  1\n",
       "2      상위 보험기금         22  1\n",
       "3        상위 투신         22  1\n",
       "4       상위 외국인         22  1\n",
       "...        ...        ... ..\n",
       "3083     물가 둔화         17  1\n",
       "3084       목 목         18  1\n",
       "3085     리 오프닝         33  1\n",
       "3086  인플레이션 둔화         31  1\n",
       "3087  특례 보금자리론         16  1\n",
       "\n",
       "[3088 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-그램\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    ngrams = []\n",
    "    for row in text:\n",
    "        words = row.split()\n",
    "        ngrams.extend([' '.join(words[i:i+n]) for i in range(len(words)-n+1)])\n",
    "    return ngrams\n",
    "\n",
    "def count_ngrams(ngrams):\n",
    "    ngram_counts = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        ngram_counts[ngram] += 1\n",
    "    return ngram_counts\n",
    "\n",
    "n = 2\n",
    "ngrams = generate_ngrams(df_A['words'], n)\n",
    "ngram_counts = count_ngrams(ngrams)\n",
    "\n",
    "# 빈도수가 15 이상인 n-gram만 선택\n",
    "selected_ngrams = {ngram: count for ngram, count in ngram_counts.items() if count >= 15}\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "selected_ngrams_df = pd.DataFrame(list(selected_ngrams.items()), columns=['ngram', 'frequency'])\n",
    "selected_ngrams_df['N'] = 1\n",
    "selected_ngrams_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
