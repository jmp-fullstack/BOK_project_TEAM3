{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "import konlpy as kn\n",
    "import MeCab as mc\n",
    "import ekonlpy as ek\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-01 00:00:00\n",
      "2024-01-30\n"
     ]
    }
   ],
   "source": [
    "day = date(2024, 3, 1)\n",
    "day_dateoffset = day - pd.DateOffset(months=1)\n",
    "print(day_dateoffset)\n",
    "\n",
    "day = date(2024, 3, 1)\n",
    "day_timedelta = day - timedelta(days=31)\n",
    "print(day_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'price', 'label']\n",
      "['2024-03-21\\t3.5290\\t-0.11\\n', '2024-03-20\\t3.5330\\t0.56\\n', '2024-03-19\\t3.5130\\t2.09\\n', '2024-03-18\\t3.4410\\t-0.66\\n', '2024-03-15\\t3.4640\\t-0.63\\n']\n"
     ]
    }
   ],
   "source": [
    "f = open('./crawl_result/call_rate.csv', 'r', encoding='utf-8')\n",
    "\n",
    "# 데이터를 완전히 동일하게 가져올 수 있는가\n",
    "headers = f.readline().rstrip() # 헤더 읽기, 맨 끝 줄바꿈기호 삭제\n",
    "print(headers.split('\\t'))\n",
    "headers = headers.split('\\t') # 같은 이름의 변수에 리스트로 바꾼 것 넣어주기\n",
    "\n",
    "# 데이터 읽기\n",
    "lines = f.readlines()\n",
    "print(lines[:5])\n",
    "\n",
    "new_datas = []\n",
    "for line in lines: # 한 줄씩 \n",
    "    data = line.rstrip().split('\\t') # 줄바꿈 기호 지우고, ,로 잘라준다.\n",
    "    dict_data = { header: data[i] for i, header in enumerate(headers) }\n",
    "    new_datas.append(dict_data) # 데이터를 딕셔너리로 만들어서 넣어야된다.\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_date(df, target_date):\n",
    "    delta = pd.Timedelta(days=1)\n",
    "    nearest_date = None,\n",
    "    min_difference = pd.Timedelta.max\n",
    "\n",
    "    for date in df['date']:\n",
    "        difference = abs(target_date - date)\n",
    "        if difference < min_difference:\n",
    "            min_difference = difference\n",
    "            nearest_date = date\n",
    "\n",
    "    return nearest_date\n",
    "\n",
    "def label_call(df):\n",
    "    df_ud = pd.DataFrame(index=df.index, columns=['date', 'price', 'label'])\n",
    "\n",
    "    # 'date' 열을 datetime 형식으로 변환\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        time = row['date']\n",
    "        time2 = time - pd.DateOffset(months=1)\n",
    "\n",
    "        # 이전 달의 날짜가 인덱스에 있는지 확인\n",
    "        if time2 in df['date'].values:\n",
    "            prev_row = df[df['date'] == time2].iloc[0]\n",
    "        else:\n",
    "            # 이전 날짜가 없는 경우 가장 가까운 날짜로 설정\n",
    "            nearest_date = find_nearest_date(df, time2)\n",
    "            prev_row = df[df['date'] == nearest_date].iloc[0]\n",
    "\n",
    "        if row['price'] > prev_row['price']:\n",
    "            label = '1'\n",
    "        elif row['price'] == prev_row['price']:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = '-1'\n",
    "            \n",
    "        df_ud.loc[i] = [time.date(), row['price'], label]\n",
    "\n",
    "    return df_ud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>3.5290</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>3.5330</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>3.5130</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-18</td>\n",
       "      <td>3.4410</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>3.4640</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3258 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   price label\n",
       "0     2024-03-21  3.5290    -1\n",
       "1     2024-03-20  3.5330    -1\n",
       "2     2024-03-19  3.5130    -1\n",
       "3     2024-03-18  3.4410    -1\n",
       "4     2024-03-15  3.4640    -1\n",
       "...          ...     ...   ...\n",
       "3253  2011-01-07  2.4900     0\n",
       "3254  2011-01-06  2.4900     0\n",
       "3255  2011-01-05  2.4900     0\n",
       "3256  2011-01-04  2.5000     1\n",
       "3257  2011-01-03  2.4900     0\n",
       "\n",
       "[3258 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(new_datas)\n",
    "\n",
    "call = label_call(df)\n",
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 분할을 위한 정규표현식 패턴\n",
    "sentence_pattern = r'(?<=[.!?]) +'\n",
    "\n",
    "# 데이터프레임으로부터 문서를 읽어와 딕셔너리 구조로 저장하는 함수\n",
    "def read_documents_to_dict(df):\n",
    "    date_dict = {}\n",
    "    change_pattern = '(?<=[가-힣])\\\\.'\n",
    "    news_pattern = ['\\\\[.*\\\\]', '\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?', '....기자']\n",
    "\n",
    "    # DataFrame의 각 행에 대해 반복\n",
    "    for index, row in df.iterrows():\n",
    "        date = str(row['date']).split(' ')[0] \n",
    "        text = row['content'] \n",
    "        \n",
    "        # 뉴스 패턴 제거\n",
    "        news_text = text\n",
    "        for pattern in news_pattern:\n",
    "            news_text = re.sub(pattern, '', news_text)\n",
    "\n",
    "        # 변경 패턴 적용\n",
    "        change_text = re.sub(change_pattern, '@@@', news_text)  \n",
    "        split_text = change_text.split('@@@')  \n",
    "        split_text = [sent.strip() for sent in split_text]\n",
    "        \n",
    "        # 문서별로 문장 추가\n",
    "        if date not in date_dict:\n",
    "            date_dict[date] = []\n",
    "        \n",
    "        # 문장 추가\n",
    "        if split_text:  # 빈 리스트인 경우 추가하지 않음\n",
    "            date_dict[date].append(split_text)\n",
    "\n",
    "    return date_dict\n",
    "\n",
    "# 문서 데이터프레임 읽기\n",
    "# -------------------------------------------------------------------------------------예시 경로 설정 필요 (여기만 건드시면 됩니다 함수 안건드셔도되요)-------------------------------------\n",
    "jong_path = \"./crawl_result/joongamg_news_test.json\"\n",
    "edaily_path = \"./crawl_result/edaily_news_test.json\"\n",
    "money_path = \"./crawl_result/moneytoday_news_test.json\"\n",
    "bone_path = \"./crawl_result/bone_report.json\"\n",
    "min_path = \"./crawl_result/minutes_re.tsv\"\n",
    "\n",
    "df_news_1 = pd.read_json(jong_path)\n",
    "df_news_2 = pd.read_json(edaily_path)\n",
    "df_news_3 = pd.read_json(money_path)\n",
    "df_bone = pd.read_json(bone_path)\n",
    "df_min = pd.read_csv(min_path, sep='\\t')\n",
    "\n",
    "# 문서들을 딕셔너리 구조로 저장\n",
    "date_dict_1 = read_documents_to_dict(df_news_1)\n",
    "date_dict_2 = read_documents_to_dict(df_news_2)\n",
    "date_dict_3 = read_documents_to_dict(df_news_3)\n",
    "date_dict_4 = read_documents_to_dict(df_bone)\n",
    "date_dict_5 = read_documents_to_dict(df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개의 딕셔너리를 합치는 함수\n",
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged_dict:\n",
    "            merged_dict[key].extend(value)  # 이미 있는 키의 경우 값들을 합침\n",
    "        else:\n",
    "            merged_dict[key] = value  # 새로운 키의 경우 값을 그대로 추가\n",
    "    return merged_dict\n",
    "\n",
    "\n",
    "\n",
    "# 두 개의 딕셔너리 합치기 -------------------------- 함수 건들지 마시고 밑에꺼에 dict 값 넣으시면 됩니다. ------------------------------------------------\n",
    "merged_date_dict_1 = merge_dicts(date_dict_1, date_dict_2)\n",
    "merged_date_dict_2 = merge_dicts(date_dict_3, date_dict_4)\n",
    "merged_date_dict_3 = merge_dicts(merged_date_dict_1, merged_date_dict_2)\n",
    "\n",
    "final_dict = merge_dicts(merged_date_dict_3, date_dict_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['스페인의 국채 낙찰금리가 또다시 하락하는 등 입찰이 호조를 이어가고 있다',\n",
       " '이탈리아 정국 혼란 속에서도 투자자들의 신뢰가 높아진 덕으로 풀이된다',\n",
       " '스페인 재무부는 14일(현지시간) 입찰을 통해 8억300유로(10억4000만달러) 어치의 국채를 발행하는데 성공했다',\n",
       " '만기가 오는 2029년인 15년물 국채의 낙찰금리는 5.224%로, 지난달 입찰에서의 5.787%에 더 낮아졌다',\n",
       " '또 만기가 2040년인 장기국채 역시 낙찰금리가 5.434%로, 지난해 12월 입찰에서의 5.893%보다 내려갔다',\n",
       " '만기 2041년 국채 역시 5.432%로, 지난 1월의 5.686%보다 낮아졌다',\n",
       " '이번 입찰은 당초 예정에 없던 것으로, 이번주초 10년만기 국채금리가 지난 2010년 11월 이후 최저수준으로 내려가자 저금리에 자금 조달을 위해 임의로 편성한 것이다',\n",
       " '제스틴 나이트 UBS 금리담당 스트래티지스트는 “스페인 재무부가 특별 입찰을 실시할 정도로 시장 내에서 국채를 인수하려는 수요가 많다는 의미”라고 평가했다',\n",
       " '실제 이날 입찰에서 만기 15년물의 경우 입찰액대비 응찰비율이 4.1배에 이르러 한 달전의 2.02배에 비해 2배 이상 수요가 늘어났다',\n",
       " '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict['2013-03-14'][0]\n",
    "####  딕셔너리 이름 [날짜] [몇번째 문서인지] [그 문서의 몇번째 문장인지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.tag import Mecab\n",
    "\n",
    "# ekonlpy의 Mecab 형태소 분석기 인스턴스 생성\n",
    "tokenizer = Mecab()\n",
    "\n",
    "# n-gram 생성 함수 정의\n",
    "def generate_ngrams(tokens, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))  # 각 n-gram을 공백으로 구분된 문자열로 결합\n",
    "    return ngrams\n",
    "\n",
    "# 토큰화 및 n-gram 생성 함수 정의\n",
    "def tokenize_with_ngrams(sentence, n):\n",
    "    tokens_with_pos = tokenizer.pos(sentence)\n",
    "    tokens = ['{}/{}'.format(token, pos) for token, pos in tokens_with_pos if pos in ['VA', 'VX', 'VV', 'NNG', 'MAG']]\n",
    "    ngrams = generate_ngrams(tokens, n)\n",
    "    return [tuple(ngram.split()) for ngram in ngrams]\n",
    "\n",
    "# 토큰화된 결과를 데이터프레임으로 출력\n",
    "token_data = {'date': [], 'document': [], 'tokens': []}\n",
    "n = 1  # n-gram의 n값 설정\n",
    "count = 0  # 출력된 결과의 수를 세는 변수\n",
    "\n",
    "for date, documents in final_dict.items():\n",
    "    for doc_num, sentences in enumerate(documents, start=1):\n",
    "        # print(f\"{date}의 문서 {doc_num} 토큰화 및 {n}-gram 생성 결과:\")\n",
    "        for sentence in sentences:\n",
    "            ngram_tokens = tokenize_with_ngrams(sentence, n)\n",
    "            token_data['date'].append(date)\n",
    "            token_data['document'].append(f\"문서 {doc_num}\")\n",
    "            token_data['tokens'].append(ngram_tokens)\n",
    "            count += 1\n",
    "            if count >= 10:  # 처음 10개의 결과만 확인하고 루프 종료\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "df = pd.DataFrame(token_data)\n",
    "df = df[df['tokens'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# df.to_csv(\"1111.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'date' 열을 datetime으로 변환\n",
    "call['date'] = pd.to_datetime(call['date'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 'date' 열을 기준으로 외부 조인 수행\n",
    "merged_df = pd.merge(call, df, on='date', how='outer')\n",
    "\n",
    "# 'key' 칼럼을 인덱스로 설정\n",
    "merged_df.set_index('date', inplace=True)\n",
    "\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'label' 칼럼의 값이 '1(매파)'인 행과 '-1(비둘기파)'인 행으로 데이터프레임 분리\n",
    "df_P = merged_df[merged_df['label'] == '1']\n",
    "df_N = merged_df[merged_df['label'] == '-1']\n",
    "\n",
    "# Nan인 행 제거\n",
    "df_P = df_P.dropna()\n",
    "df_N = df_N.dropna()\n",
    "\n",
    "# 필요없는 열 제거 \n",
    "df_P = df_P.drop(['price'], axis=1) # 'date'\n",
    "df_N = df_N.drop(['price'], axis=1) # 'date'\n",
    "\n",
    "# word_df = pd.concat([df_P,df_N],axis=0)\n",
    "# x_tain = word_df[\"words\"]\n",
    "# y_tain = word_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P = df_P.rename(columns={'label': 'P'})\n",
    "df_P\n",
    "df_P.to_csv(\"df_P_5gram.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_N = df_N.rename(columns={'label': 'N'})\n",
    "df_N\n",
    "df_N.to_csv(\"df_N_5gram.csv\", mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
