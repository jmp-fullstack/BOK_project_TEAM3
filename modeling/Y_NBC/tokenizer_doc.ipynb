{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "import konlpy as kn\n",
    "import MeCab as mc\n",
    "import ekonlpy as ek\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-01 00:00:00\n",
      "2024-01-30\n"
     ]
    }
   ],
   "source": [
    "day = date(2024, 3, 1)\n",
    "day_dateoffset = day - pd.DateOffset(months=1)\n",
    "print(day_dateoffset)\n",
    "\n",
    "day = date(2024, 3, 1)\n",
    "day_timedelta = day - timedelta(days=31)\n",
    "print(day_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'price', 'label']\n",
      "['2024-03-21\\t3.5290\\t-0.11\\n', '2024-03-20\\t3.5330\\t0.56\\n', '2024-03-19\\t3.5130\\t2.09\\n', '2024-03-18\\t3.4410\\t-0.66\\n', '2024-03-15\\t3.4640\\t-0.63\\n']\n"
     ]
    }
   ],
   "source": [
    "f = open('./crawl_result/call_rate.csv', 'r', encoding='utf-8')\n",
    "\n",
    "# 데이터를 완전히 동일하게 가져올 수 있는가\n",
    "headers = f.readline().rstrip() # 헤더 읽기, 맨 끝 줄바꿈기호 삭제\n",
    "print(headers.split('\\t'))\n",
    "headers = headers.split('\\t') # 같은 이름의 변수에 리스트로 바꾼 것 넣어주기\n",
    "\n",
    "# 데이터 읽기\n",
    "lines = f.readlines()\n",
    "print(lines[:5])\n",
    "\n",
    "new_datas = []\n",
    "for line in lines: # 한 줄씩 \n",
    "    data = line.rstrip().split('\\t') # 줄바꿈 기호 지우고, ,로 잘라준다.\n",
    "    dict_data = { header: data[i] for i, header in enumerate(headers) }\n",
    "    new_datas.append(dict_data) # 데이터를 딕셔너리로 만들어서 넣어야된다.\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_date(df, target_date):\n",
    "    delta = pd.Timedelta(days=1)\n",
    "    nearest_date = None,\n",
    "    min_difference = pd.Timedelta.max\n",
    "\n",
    "    for date in df['date']:\n",
    "        difference = abs(target_date - date)\n",
    "        if difference < min_difference:\n",
    "            min_difference = difference\n",
    "            nearest_date = date\n",
    "\n",
    "    return nearest_date\n",
    "\n",
    "def label_call(df):\n",
    "    df_ud = pd.DataFrame(index=df.index, columns=['date', 'price', 'label'])\n",
    "\n",
    "    # 'date' 열을 datetime 형식으로 변환\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        time = row['date']\n",
    "        time2 = time - pd.DateOffset(months=1)\n",
    "\n",
    "        # 이전 달의 날짜가 인덱스에 있는지 확인\n",
    "        if time2 in df['date'].values:\n",
    "            prev_row = df[df['date'] == time2].iloc[0]\n",
    "        else:\n",
    "            # 이전 날짜가 없는 경우 가장 가까운 날짜로 설정\n",
    "            nearest_date = find_nearest_date(df, time2)\n",
    "            prev_row = df[df['date'] == nearest_date].iloc[0]\n",
    "\n",
    "        if row['price'] > prev_row['price']:\n",
    "            label = '1'\n",
    "        elif row['price'] == prev_row['price']:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = '-1'\n",
    "            \n",
    "        df_ud.loc[i] = [time.date(), row['price'], label]\n",
    "\n",
    "    return df_ud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>3.5290</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>3.5330</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>3.5130</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-18</td>\n",
       "      <td>3.4410</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>3.4640</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>2.4900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3258 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   price label\n",
       "0     2024-03-21  3.5290    -1\n",
       "1     2024-03-20  3.5330    -1\n",
       "2     2024-03-19  3.5130    -1\n",
       "3     2024-03-18  3.4410    -1\n",
       "4     2024-03-15  3.4640    -1\n",
       "...          ...     ...   ...\n",
       "3253  2011-01-07  2.4900     0\n",
       "3254  2011-01-06  2.4900     0\n",
       "3255  2011-01-05  2.4900     0\n",
       "3256  2011-01-04  2.5000     1\n",
       "3257  2011-01-03  2.4900     0\n",
       "\n",
       "[3258 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(new_datas)\n",
    "\n",
    "call = label_call(df)\n",
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 분할을 위한 정규표현식 패턴\n",
    "sentence_pattern = r'(?<=[.!?]) +'\n",
    "\n",
    "# 데이터프레임으로부터 문서를 읽어와 딕셔너리 구조로 저장하는 함수\n",
    "def read_documents_to_dict(df):\n",
    "    date_dict = {}\n",
    "    change_pattern = '(?<=[가-힣])\\\\.'\n",
    "    news_pattern = ['\\\\[.*\\\\]', '\\\\w{4,}\\\\@[a-zA-Z0-9\\\\-]{2,}\\\\.[a-z]{2,}(\\\\.[a-z]{2})?', '....기자']\n",
    "\n",
    "    # DataFrame의 각 행에 대해 반복\n",
    "    for index, row in df.iterrows():\n",
    "        date = str(row['date']).split(' ')[0] \n",
    "        text = row['content'] \n",
    "        \n",
    "        # 뉴스 패턴 제거\n",
    "        news_text = text\n",
    "        for pattern in news_pattern:\n",
    "            news_text = re.sub(pattern, '', news_text)\n",
    "\n",
    "        # 변경 패턴 적용\n",
    "        change_text = re.sub(change_pattern, '@@@', news_text)  \n",
    "        split_text = change_text.split('@@@')  \n",
    "        split_text = [sent.strip() for sent in split_text]\n",
    "        \n",
    "        # 문서별로 문장 추가\n",
    "        if date not in date_dict:\n",
    "            date_dict[date] = []\n",
    "        \n",
    "        # 문장 추가\n",
    "        if split_text:  # 빈 리스트인 경우 추가하지 않음\n",
    "            date_dict[date].append(split_text)\n",
    "\n",
    "    return date_dict\n",
    "\n",
    "# 문서 데이터프레임 읽기\n",
    "# -------------------------------------------------------------------------------------예시 경로 설정 필요 (여기만 건드시면 됩니다 함수 안건드셔도되요)-------------------------------------\n",
    "jong_path = \"./crawl_result/joongamg_news_test.json\"\n",
    "edaily_path = \"./crawl_result/edaily_news_test.json\"\n",
    "money_path = \"./crawl_result/moneytoday_news_test.json\"\n",
    "bone_path = \"./crawl_result/bone_report.json\"\n",
    "min_path = \"./crawl_result/minutes_re.tsv\"\n",
    "\n",
    "df_news_1 = pd.read_json(jong_path)\n",
    "df_news_2 = pd.read_json(edaily_path)\n",
    "df_news_3 = pd.read_json(money_path)\n",
    "df_bone = pd.read_json(bone_path)\n",
    "df_min = pd.read_csv(min_path, sep='\\t')\n",
    "\n",
    "# 문서들을 딕셔너리 구조로 저장\n",
    "date_dict_1 = read_documents_to_dict(df_news_1)\n",
    "date_dict_2 = read_documents_to_dict(df_news_2)\n",
    "date_dict_3 = read_documents_to_dict(df_news_3)\n",
    "date_dict_4 = read_documents_to_dict(df_bone)\n",
    "date_dict_5 = read_documents_to_dict(df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개의 딕셔너리를 합치는 함수\n",
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged_dict:\n",
    "            merged_dict[key].extend(value)  # 이미 있는 키의 경우 값들을 합침\n",
    "        else:\n",
    "            merged_dict[key] = value  # 새로운 키의 경우 값을 그대로 추가\n",
    "    return merged_dict\n",
    "\n",
    "\n",
    "\n",
    "# 두 개의 딕셔너리 합치기 -------------------------- 함수 건들지 마시고 밑에꺼에 dict 값 넣으시면 됩니다. ------------------------------------------------\n",
    "merged_date_dict_1 = merge_dicts(date_dict_1, date_dict_2)\n",
    "merged_date_dict_2 = merge_dicts(date_dict_3, date_dict_4)\n",
    "merged_date_dict_3 = merge_dicts(merged_date_dict_1, merged_date_dict_2)\n",
    "\n",
    "final_dict = merge_dicts(merged_date_dict_3, date_dict_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['스페인의 국채 낙찰금리가 또다시 하락하는 등 입찰이 호조를 이어가고 있다',\n",
       " '이탈리아 정국 혼란 속에서도 투자자들의 신뢰가 높아진 덕으로 풀이된다',\n",
       " '스페인 재무부는 14일(현지시간) 입찰을 통해 8억300유로(10억4000만달러) 어치의 국채를 발행하는데 성공했다',\n",
       " '만기가 오는 2029년인 15년물 국채의 낙찰금리는 5.224%로, 지난달 입찰에서의 5.787%에 더 낮아졌다',\n",
       " '또 만기가 2040년인 장기국채 역시 낙찰금리가 5.434%로, 지난해 12월 입찰에서의 5.893%보다 내려갔다',\n",
       " '만기 2041년 국채 역시 5.432%로, 지난 1월의 5.686%보다 낮아졌다',\n",
       " '이번 입찰은 당초 예정에 없던 것으로, 이번주초 10년만기 국채금리가 지난 2010년 11월 이후 최저수준으로 내려가자 저금리에 자금 조달을 위해 임의로 편성한 것이다',\n",
       " '제스틴 나이트 UBS 금리담당 스트래티지스트는 “스페인 재무부가 특별 입찰을 실시할 정도로 시장 내에서 국채를 인수하려는 수요가 많다는 의미”라고 평가했다',\n",
       " '실제 이날 입찰에서 만기 15년물의 경우 입찰액대비 응찰비율이 4.1배에 이르러 한 달전의 2.02배에 비해 2배 이상 수요가 늘어났다',\n",
       " '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict['2013-03-14'][0]\n",
    "####  딕셔너리 이름 [날짜] [몇번째 문서인지] [그 문서의 몇번째 문장인지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.tag import Mecab\n",
    "\n",
    "# ekonlpy의 Mecab 형태소 분석기 인스턴스 생성\n",
    "tokenizer = Mecab()\n",
    "\n",
    "# n-gram 생성 함수 정의\n",
    "def generate_ngrams(tokens, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))  # 각 n-gram을 공백으로 구분된 문자열로 결합\n",
    "    return ngrams\n",
    "\n",
    "# 토큰화 및 n-gram 생성 함수 정의\n",
    "def tokenize_with_ngrams(sentence, n):\n",
    "    tokens_with_pos = tokenizer.pos(sentence)\n",
    "    tokens = ['{}/{}'.format(token, pos) for token, pos in tokens_with_pos if pos in ['VA', 'VX', 'VV', 'NNG', 'MAG']]\n",
    "    ngrams = generate_ngrams(tokens, n)\n",
    "    return [tuple(ngram.split()) for ngram in ngrams]\n",
    "\n",
    "# 토큰화된 결과를 데이터프레임으로 출력\n",
    "token_data = {'date': [], 'document': [], 'tokens': []}\n",
    "n = 1  # n-gram의 n값 설정\n",
    "count = 0  # 출력된 결과의 수를 세는 변수\n",
    "\n",
    "for date, documents in final_dict.items():\n",
    "    for doc_num, sentences in enumerate(documents, start=1):\n",
    "        # print(f\"{date}의 문서 {doc_num} 토큰화 및 {n}-gram 생성 결과:\")\n",
    "        for sentence in sentences:\n",
    "            ngram_tokens = tokenize_with_ngrams(sentence, n)\n",
    "            token_data['date'].append(date)\n",
    "            token_data['document'].append(f\"문서 {doc_num}\")\n",
    "            token_data['tokens'].append(ngram_tokens)\n",
    "            count += 1\n",
    "            if count >= 10:  # 처음 10개의 결과만 확인하고 루프 종료\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "df = pd.DataFrame(token_data)\n",
    "df = df[df['tokens'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# df.to_csv(\"1111.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'date' 열을 datetime으로 변환\n",
    "call['date'] = pd.to_datetime(call['date'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 'date' 열을 기준으로 외부 조인 수행\n",
    "merged_df = pd.merge(call, df, on='date', how='outer')\n",
    "\n",
    "# 'key' 칼럼을 인덱스로 설정\n",
    "merged_df.set_index('date', inplace=True)\n",
    "\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'label' 칼럼의 값이 '1(매파)'인 행과 '-1(비둘기파)'인 행으로 데이터프레임 분리\n",
    "df_P = merged_df[merged_df['label'] == '1']\n",
    "df_N = merged_df[merged_df['label'] == '-1']\n",
    "\n",
    "# Nan인 행 제거\n",
    "df_P = df_P.dropna()\n",
    "df_N = df_N.dropna()\n",
    "\n",
    "# 필요없는 열 제거 \n",
    "df_P = df_P.drop(['price'], axis=1) # 'date'\n",
    "df_N = df_N.drop(['price'], axis=1) # 'date'\n",
    "\n",
    "# word_df = pd.concat([df_P,df_N],axis=0)\n",
    "# x_tain = word_df[\"words\"]\n",
    "# y_tain = word_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P = df_P.rename(columns={'label': 'P'})\n",
    "df_P\n",
    "df_P.to_csv(\"df_P_5gram.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_N = df_N.rename(columns={'label': 'N'})\n",
    "df_N\n",
    "df_N.to_csv(\"df_N_5gram.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>경로NNG</td>\n",
       "      <td>571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>보임VV</td>\n",
       "      <td>472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>금통위NNG</td>\n",
       "      <td>437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내수NNG</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>경제NNG</td>\n",
       "      <td>4113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>스페인NNG</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>양도NNG</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>대지진NNG</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>통안1년NNG</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>보입니다VV</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1868 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ngram  frequency  P\n",
       "0       경로NNG        571  1\n",
       "1        보임VV        472  1\n",
       "2      금통위NNG        437  1\n",
       "3       내수NNG        408  1\n",
       "4       경제NNG       4113  1\n",
       "...       ...        ... ..\n",
       "1863   스페인NNG         33  1\n",
       "1864    양도NNG         34  1\n",
       "1865   대지진NNG         41  1\n",
       "1866  통안1년NNG         84  1\n",
       "1867   보입니다VV         41  1\n",
       "\n",
       "[1868 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P 1-gram\n",
    "def generate_ngrams(text_list, n):\n",
    "    ngrams = []\n",
    "    for text in text_list:\n",
    "        ngrams.extend([''.join(text[i:i+n]).replace(' ', '') for i in range(len(text)-n+1)])\n",
    "    return ngrams\n",
    "\n",
    "def count_ngrams(ngrams):\n",
    "    ngram_counts = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        ngram_counts[ngram] += 1\n",
    "    return ngram_counts\n",
    "\n",
    "# tokens 열의 데이터를 문자열로 변환\n",
    "df_P['tokens'] = df_P['tokens'].apply(lambda x: [''.join(token).replace(' ', '') for token in x])\n",
    "\n",
    "n = 1\n",
    "ngrams = generate_ngrams(df_P['tokens'], n)\n",
    "ngram_counts = count_ngrams(ngrams)\n",
    "\n",
    "# 빈도수가 30 이상인 n-gram만 선택\n",
    "selected_ngrams = {ngram: count for ngram, count in ngram_counts.items() if count >= 30}\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "P_1gram_df = pd.DataFrame(list(selected_ngrams.items()), columns=['ngram', 'frequency'])\n",
    "P_1gram_df['P'] = 1\n",
    "P_1gram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지난VV</td>\n",
       "      <td>1196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일NNG</td>\n",
       "      <td>2188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>오후NNG</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>업NNG</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비트코인NNG</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>캐리트레이드NNG</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>그리스사태NNG</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>인해서VV</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>모기지론NNG</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>밝혔으며VV</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ngram  frequency  N\n",
       "0          지난VV       1196  1\n",
       "1          일NNG       2188  1\n",
       "2         오후NNG         49  1\n",
       "3          업NNG         73  1\n",
       "4       비트코인NNG         65  1\n",
       "...         ...        ... ..\n",
       "2205  캐리트레이드NNG         31  1\n",
       "2206   그리스사태NNG         43  1\n",
       "2207      인해서VV         30  1\n",
       "2208    모기지론NNG        103  1\n",
       "2209     밝혔으며VV         40  1\n",
       "\n",
       "[2210 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P 1-gram\n",
    "def generate_ngrams(text_list, n):\n",
    "    ngrams = []\n",
    "    for text in text_list:\n",
    "        ngrams.extend([''.join(text[i:i+n]).replace(' ', '') for i in range(len(text)-n+1)])\n",
    "    return ngrams\n",
    "\n",
    "def count_ngrams(ngrams):\n",
    "    ngram_counts = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        ngram_counts[ngram] += 1\n",
    "    return ngram_counts\n",
    "\n",
    "# tokens 열의 데이터를 문자열로 변환\n",
    "df_N['tokens'] = df_N['tokens'].apply(lambda x: [''.join(token).replace(' ', '') for token in x])\n",
    "\n",
    "n = 1\n",
    "ngrams = generate_ngrams(df_N['tokens'], n)\n",
    "ngram_counts = count_ngrams(ngrams)\n",
    "\n",
    "# 빈도수가 30 이상인 n-gram만 선택\n",
    "selected_ngrams = {ngram: count for ngram, count in ngram_counts.items() if count >= 30}\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "N_1gram_df = pd.DataFrame(list(selected_ngrams.items()), columns=['ngram', 'frequency'])\n",
    "N_1gram_df['N'] = 1\n",
    "N_1gram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ngram'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10876\\552377174.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_1gram_df\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mN_1gram_df\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ngram'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'N'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'frequency_x'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'P_count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'frequency_y'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'N_count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SDA11\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 148\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SDA11\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    733\u001b[0m         (\n\u001b[0;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m         \u001b[1;31m# to avoid incompatible dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SDA11\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1199\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\SDA11\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ngram'"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(P_1gram_df , N_1gram_df , on='ngram', how='inner')\n",
    "merged_df = merged_df.drop(['P', 'N'], axis=1) \n",
    "merged_df = merged_df.rename(columns={'frequency_x': 'P_count'})\n",
    "merged_df = merged_df.rename(columns={'frequency_y': 'N_count'})\n",
    "merged_df.set_index('ngram', inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.to_csv(\"final_count_1.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ----------------------------------------------------------- 2_gram ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>frequency</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>순매수 상위</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>순매도 상위</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>상위 보험기금</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>상위 투신</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>상위 외국인</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>물가 둔화</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>목 목</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>리 오프닝</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>인플레이션 둔화</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>특례 보금자리론</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3088 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ngram  frequency  N\n",
       "0       순매수 상위         44  1\n",
       "1       순매도 상위         44  1\n",
       "2      상위 보험기금         22  1\n",
       "3        상위 투신         22  1\n",
       "4       상위 외국인         22  1\n",
       "...        ...        ... ..\n",
       "3083     물가 둔화         17  1\n",
       "3084       목 목         18  1\n",
       "3085     리 오프닝         33  1\n",
       "3086  인플레이션 둔화         31  1\n",
       "3087  특례 보금자리론         16  1\n",
       "\n",
       "[3088 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-gram\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    ngrams = []\n",
    "    for row in text:\n",
    "        words = row.split()\n",
    "        ngrams.extend([' '.join(words[i:i+n]) for i in range(len(words)-n+1)])\n",
    "    return ngrams\n",
    "\n",
    "def count_ngrams(ngrams):\n",
    "    ngram_counts = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        ngram_counts[ngram] += 1\n",
    "    return ngram_counts\n",
    "\n",
    "n = 2\n",
    "ngrams = generate_ngrams(df_P['words'], n)\n",
    "ngram_counts = count_ngrams(ngrams)\n",
    "\n",
    "# 빈도수가 15 이상인 n-gram만 선택\n",
    "selected_ngrams = {ngram: count for ngram, count in ngram_counts.items() if count >= 15}\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "selected_ngrams_df = pd.DataFrame(list(selected_ngrams.items()), columns=['ngram', 'frequency'])\n",
    "selected_ngrams_df['N'] = 1\n",
    "selected_ngrams_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
