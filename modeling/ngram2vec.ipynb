{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seedwords ##\n",
    "\n",
    "# doveish : []\n",
    "# hawkish : []\n",
    "\n",
    "# NBC에서 구한 단어 사전을 가지고 시작한다. \n",
    "\n",
    "# 중심단어 5 , 맥락단어5, 원도우크기5, 부정적샘플링 크기5, 벡터 차원30\n",
    "\n",
    "# NBC 모델을 사용하여 \"doveish\"와 \"hawkish\"에 해당하는 단어들을 추출\n",
    "# 추출된 단어들을 중심 단어와 맥락 단어로 사용하여 Word2Vec 모델을 학습하거나, 이미 학습된 Word2Vec 모델을 로드\n",
    "# Word2Vec 모델을 사용하여 각 단어에 대한 벡터를 얻어옵니다.\n",
    "# \"doveish\"와 \"hawkish\"에 해당하는 단어들의 벡터를 이용하여 유사한 단어들을 추출하고, 이를 seedwords로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec 모델 로드\n",
    "word2vec_model = Word2Vec.load('your_word2vec_model_path')\n",
    "\n",
    "# 주어진 단어의 유사한 단어들을 추출하는 함수 정의\n",
    "def get_similar_words(word, topn=5):\n",
    "    # 주어진 단어와 가장 유사한 상위 topn개의 단어 추출\n",
    "    similar_words = word2vec_model.wv.most_similar(word, topn=topn)\n",
    "    # 추출된 단어들 반환\n",
    "    return [word for word, _ in similar_words]\n",
    "\n",
    "# NBC 모델을 사용하여 \"doveish\"와 \"hawkish\"에 해당하는 단어들 추출\n",
    "doveish_words = ['dove', 'peaceful', 'pacifist', 'conciliatory']  # NBC 모델을 통해 추출된 단어들로 가정\n",
    "hawkish_words = ['hawk', 'aggressive', 'militant', 'bellicose']  # NBC 모델을 통해 추출된 단어들로 가정\n",
    "\n",
    "# 주어진 단어들의 유사한 단어들을 추출하여 seedwords로 사용\n",
    "doveish_seedwords = [word for seedword in doveish_words for word in get_similar_words(seedword)]\n",
    "hawkish_seedwords = [word for seedword in hawkish_words for word in get_similar_words(seedword)]\n",
    "\n",
    "# seedwords 출력\n",
    "print(\"doveish seedwords:\", doveish_seedwords)\n",
    "print(\"hawkish seedwords:\", hawkish_seedwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "# 학습에 사용할 데이터 (2-gram 형식)\n",
    "sentences = [['this is', 'is a', 'a sample', 'sample sentence'],\n",
    "             ['this is', 'is another', 'another example', 'example sentence'],\n",
    "             ['yet another', 'another sentence'],\n",
    "             ['one more', 'more sentence']]\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "model = Word2Vec(sentences,\n",
    "                 sg=1,                  # Skip-gram 모델 사용 (CBOW 모델의 경우 sg=0)\n",
    "                 window=5,              # 원도우 크기 설정\n",
    "                 negative=5,            # 부정적 샘플링 크기 설정\n",
    "                 vector_size=300,        # 벡터 차원 설정\n",
    "                 min_count=1,           # 최소 단어 빈도 설정\n",
    "                 workers=4)             # 학습에 사용할 CPU 코어 수\n",
    "\n",
    "# 'this' 단어의 벡터 확인\n",
    "print(\"Vector representation of 'this':\", model.wv['this is', 'is a', 'a sample', 'sample sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
